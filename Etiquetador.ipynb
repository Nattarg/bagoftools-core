{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Etiquetador V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nattarg/bagoftools-core/blob/master/Etiquetador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIHQyY8sEFy8",
        "colab_type": "text"
      },
      "source": [
        "#Etiquetador utilizando spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD4DcTMmGIuW",
        "colab_type": "text"
      },
      "source": [
        "Primeiro importamos a biblioteca spacy e carregamos os arquivos para utilizar a biblioteca em português. \n",
        "```\n",
        "import spacy\n",
        "!python -m spacy download pt\n",
        "```\n",
        "Em seguida definimos a função que irá etiquetar as palavras, para tal se fazela necessiário o parâmetro texto.\n",
        "```\n",
        "def etiquetador(texto):\n",
        "```\n",
        "Criamos então a variável nlp para guardar as \"regras\" da linguagem a ser trabalhada. **É importante lembrar que os proxímos codigos (até o return) estão identados dentro da função criada**.\n",
        "```\n",
        "nlp = spacy.load('pt)\n",
        "```\n",
        "Em sequência covertemos o texto para o formato doc e armazenamos este valor na variável doc.\n",
        "```\n",
        "doc = nlp(texto)\n",
        "```\n",
        "Após isso, utilizamos o laço for para guardar os valores **orth_** (forma ortográfica) e **pos_**(etiquetagem morfológica) das palavras do texto convertido para doc em um vetor \"etiq\".\n",
        "```\n",
        "etiq = [(token.orth_, token.pos_) for token in doc]\n",
        "```\n",
        "Por fim enviamos retornamos o valor da função (a variável etiq) através do metodo return.\n",
        "```\n",
        "return etiq;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLxZ6W-OIUG0",
        "colab_type": "text"
      },
      "source": [
        "Também foi criado uma função para teste do funcionamento do tokenizador. Porém diferente do caso anterior não se faz necessário nenhum parâmetro.\n",
        "```\n",
        "def teste_etiquetador():\n",
        "```\n",
        "O código é bem simples, ele define o texto e exibi o texto pré-definido para o usuário.\n",
        "```\n",
        "texto = 'Texto para testar o etiquetador !'\n",
        "print(texto)\n",
        "```\n",
        "Em sequência utilizamos a função ja criada em conjunto com o print.\n",
        "```\n",
        "print(etiquetador(texto))\n",
        "```\n",
        "Esta função não tem retorno. Porém podemos testar o etiquetador \"chamando\" ele.\n",
        "```\n",
        "teste_etiquetador()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59tEaglLD_DF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0a7f874d-7fdc-4cf0-c3cc-1a14192e6776"
      },
      "source": [
        "import spacy\n",
        "!python -m spacy download pt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pt_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.1.0/pt_core_news_sm-2.1.0.tar.gz#egg=pt_core_news_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktD9MLb4FLQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def v(texto):\n",
        "  nlp = spacy.load('pt')\n",
        "  doc = nlp(texto)\n",
        "  etiq = [(token.orth_, token.pos_) for token in doc]\n",
        "  return etiq;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuQvp2V3FLF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def teste_etiquetador():\n",
        "  texto =  'Texto para testar o etiquetador !'\n",
        "  print(texto)\n",
        "  print(etiquetador(texto))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5GZw1IpFK5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43840fec-c4e7-462a-b794-277af9075657"
      },
      "source": [
        "teste_etiquetador()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto para testar o tokenizador !\n",
            "[('Texto', 'NOUN'), ('para', 'ADP'), ('testar', 'VERB'), ('o', 'DET'), ('tokenizador', 'NOUN'), ('!', 'PUNCT')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}